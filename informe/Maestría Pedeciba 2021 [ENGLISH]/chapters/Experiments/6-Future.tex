
\section{Future Work}
\label{secX:future}


In the current section we propose some ideas to carry out as future work. In our experiments, which are presented in Chapter~\ref{experiments}, we asses the compression performance of the implemented algorithms through the CR metric (recall Definition~\ref{def:compression-rate}). It would be interesting to consider additional metrics, such as the \textit{root mean square error (RMSE)}, which measures the approximation error between the original and the decoded signals, or the computational time, and the sensitivity to outliers \cite{AnEva2013}. We could also consider additional datasets, which would increase the running time of our experiments, but may provide new insights regarding the compression performance of the implemented algorithms.


The results presented in Section~\ref{secX:codersmask} reveal \textit{which} of the implemented algorithms obtains better compression results for each data type in the experimental datasets. It would be useful to analyze \textit{why} is it the case that a certain algorithm achieves better results for a certain data type. In order to do this, we would need to examine the signals for each data type, analyze their characteristics (e.g. whether they are slowly varying or rough signals, the amount of outliers, periodicity), and observe if there is any relation between these characteristics and the algorithm that obtains the best compression performance. This would be useful, so that in the future we might be able to predict which algorithm is better for compressing certain signal, only by analyzing the signal's characteristics, and without the need of running the whole batch of algorithms to compare the compression results obtained in each case. If, given certain statistics of a signal, we could programmatically select a good compression algorithm for the signal, this could prove to be beneficial for online compression, as it would allow us to select a different compression algorithm as the trends in the signal change over time.


In Section~\ref{algo:details} we mention that we focus on the compression of the sample columns of the datasets, and do not delve into the optimization of the timestamp compression. This is task that it would be interesting to approach in the future as well.



% Some ideas:
% \vspace{-10pt}
% \begin{itemize}
%     \item Consider non-linear models (e.g. Chebyshev Approximation)
%     \item Create universal coder, with every algorithm as a subroutine
% \end{itemize}
