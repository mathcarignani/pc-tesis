
\clearpage
\section{Comparison of Masking and Non-Masking Variants}
\label{secX:rendimiento-relativo}


In this section, we compare the compression performance of the masking and non-masking variants of every coding algorithm in $A_M$ (recall this definition from the first paragraph in Section~\ref{experiments:experiments}). Specifically, we compare:


\vspace{-6pt}
\newcommand{\against}[1]{$\text{{#1}}_\textit{M}$ against $\text{{#1}}_\textit{NM}$}
\begin{itemize}
    \item \against{PCA}
    \item \against{APCA}
    \item \against{CA}
    \item \against{PWLH}
    \item \against{PWLHInt}
    \item \against{GAMPS}
\end{itemize}


\vspace{+3pt}
For each algorithm $a \in A_M$, and each error parameter $e \in E$, we compare the performance of $a_\maskalgo$ and $a_\NOmaskalgo$. For the purpose of this comparison, we choose the most favorable window size for each variant $a_v$, in the sense of the following definition.


\vspace{+5pt}
\begin{defcion}
\label{def:ows}
The \textit{optimal window size (\owsit)} of a coding algorithm variant $a_v \in V$, and an error parameter $e \in E$, for the data type $z$ of a certain dataset $d$, is given by
\begin{equation}
\label{eq:ows}
\ows(a_v, e, z, d) = \argmin_{w\ \in \ W} \biggl\{ \CR(c_{<a_v, w, e>}, z, d) \biggr\},
\end{equation}
where we break ties in favor of the smallest window size.
\end{defcion}


For each data type $z$ of each dataset $d$, and each coding algorithm $a \in A_M$ and error parameter $e \in E$, we calculate the RD between $c_{<a_\maskalgo, w_\maskalgo^{*}, e>}$ and $c_{<a_\NOmaskalgo, w_\NOmaskalgo^{*}, e>}$, as defined in~(\ref{eq:relative-difference-dataset}), where $w_\maskalgo^{*}=\owsns(a_\maskalgo, e, z, d)$ and $w_\NOmaskalgo^{*}=\owsns(a_\NOmaskalgo, e, z, d)$.


\vspace{+2pt}
As an example, in figures~\ref{fig:diff-sst} and~\ref{fig:diff-tornado} we show the CR and the RD, as a function of the error parameter, obtained for two data types of two different datasets. Figure~\ref{fig:diff-sst} shows the results for the data type $z=$~``SST" of the dataset $d=$~\datasetsst, presented in Section~\ref{datasets:sst}, and Figure~\ref{fig:diff-tornado} shows the results for the data type $z=$~``Longitude" of the dataset $d=$~\datasettornado, presented in Section~\ref{datasets:tornado}. In Figure~\ref{fig:diff-sst} we observe a large RD favoring the masking variant for all tested algorithms. On the other hand, in Figure~\ref{fig:diff-tornado} we observe that the non-masking variant outperforms the masking variant for all algorithms. We notice, however, that the RD is very small in the latter case.


\clearpage

\input{appendices/commands.tex}
\threetwosingle{2-NOAA-SST-1}{\datasetsst}{SST}{\threetwomost}{\label{fig:diff-sst}}
\threetwosingle{7-NOAA-SPC-tornado-2}{\datasettornado}{Longitude}{\threetwoleast}{\label{fig:diff-tornado}}

\clearpage


\newcommand{\errParVal}{8 different error parameter values}
We analyze the experimental results to compare the performance of the masking and non-masking variants of each algorithm. For each data type, we iterate through each algorithm $a \in A_M$, and each error parameter $e \in E$, and we calculate the RD between the CAIs $c_{<a_\maskalgo, w_\maskalgo^{*}, e>}$ and $c_{<a_\NOmaskalgo, w_\NOmaskalgo^{*}, e>}$, obtained by setting the OWS for the masking variant $a_\maskalgo$ and the non-masking variant $a_\NOmaskalgo$, respectively. Since we consider \errParVal\ and there are 6 algorithms in $A_M$, for each data type we compare a total of 48 pairs of CAIs. Table~\ref{tabla:rendimiento-relativ-NM-M} summarizes the results of these comparisons, aggregated by dataset. The number of pairs of CAIs evaluated for each dataset depends on the number of different data types it contains.


\vspace{+5pt}
\input{chapters/4-Experiments/python/table-relative.tex}
\vspace{-5pt}


Consider, for example, the results for the dataset Wind, in the last row. The second column shows that there are no gaps in any of the data types of the dataset (recall the dataset information from Table~\ref{datasets:table:overview}). Since the dataset has three data types, we compare a total of $3\times48=144$ pairs of CAIs. The third column reveals that in none of these comparisons the masking variant $a_\maskalgo$ outperforms the non-masking variant $a_\NOmaskalgo$, i.e. the RD is always negative. The last column shows the range for the values attained by the RD for those tested CAIs.


Observing the last column of Table~\ref{tabla:rendimiento-relativ-NM-M}, we notice that, in every case in which the non-masking variant performs best, the RD is close to zero. The minimum value it takes is $-0.29\%$, which is obtained for the data type ``Longitude" of the dataset \datasettornado, with algorithm APCA, and error parameter $e=30$. In Figure~\ref{fig:diff-tornado} we highlight the marker associated to this minimum with a blue circle. On the other hand, we observe that, for the datasets in which the masking variant performs best, the RD reaches high absolute values. The maximum ($50.78\%$) is obtained for the data type ``VWC" of the dataset \datasetsst, with algorithm PCA, and error parameter $e=30$, which is highlighted in Figure~\ref{fig:diff-sst} with a red circle.


\newcommand{\vaster}{V^*}
The experimental results presented in this section suggest that if we were interested in compressing a dataset with many gaps, we would benefit from using the masking variant of an algorithm, $a_\maskalgo$. However, even if the dataset didn't have any gaps, the performance would not be significantly worse than that obtained by using the non-masking variant of the algorithm, $a_\NOmaskalgo$. Therefore, since masking variants are, in general, more robust in this sense, in the sequel we focus on the set of variants $\vaster$ that we define next.


\vspace{+5pt}
\begin{defcion}
\label{defcion:vaster}
We denote by $\vaster$ the set of all the masking algorithm variants $a_\maskalgo$ for $a \in A$.
\end{defcion}


Notice that $\vaster$ includes a single variant for each algorithm. Therefore, in what follows we sometimes refer to the elements of $\vaster$ simply as algorithms.

