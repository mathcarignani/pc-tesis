%----------------------------------------------------------------------------------------
%	ABSTRACT PAGE
%----------------------------------------------------------------------------------------
\newcommand{\maskalgo}{\textit{M}\xspace}
\newcommand{\NOmaskalgo}{\textit{NM}\xspace}

\addtotoc{Abstract} % Add the "Abstract" page entry to the Contents

\abstract{\addtocontents{toc}{\vspace{0.3em}} % Add a gap in the Contents, for aesthetics

The staggering development of mobile communications and the Internet has contributed to a rapid increase in the amount of digital data created and replicated worldwide, which is estimated to double every three years. In this context, data compression algorithms, which allow to reduce the number of bits needed to represent certain digital data, have become increasingly relevant. In this work, we focus on the compression of multichannel signals with irregular sampling rate and data gaps. We consider the state-of-the-art algorithms, which are used to compress gapless signals with regular sampling, adapt them to operate with signals with irregular sampling rate and data gaps, then evaluate their performance experimentally, through the compression of signals obtained from real-world datasets. Both the original and our adapted algorithms work in a near-lossless fashion, guaranteeing a bounded per-sample absolute error between the decompressed and the original signals, and they compress signals by exploiting correlation among signal samples taken at close times (temporal correlation), and, in some cases, among samples from various signals (spatial correlation). For most algorithms we design and implement two variants: the masking (\maskalgo) variant, which first encodes the position of all the gaps, and then proceeds to encode the data values separately, and the non-masking (\NOmaskalgo) variant, which encodes the gaps and the data values together. For each algorithm, we compare the compression performance of both variants: our experimental results suggest that variant \maskalgo is more robust and performs better in general. Every implemented algorithm variant depends on a window size parameter, which defines the size of the blocks into which the data are partitioned for encoding. We analyze the sensibility of variant \maskalgo of each algorithm to this parameter: for each dataset, we compress each data file, and compare the results obtained when using a window size optimized for said specific file, against the results obtained when using a window size optimized for the whole dataset. Our experimental results indicate that the difference in compression performance is generally rather small. The last part of our experimental analysis consists in comparing the compression performance achieved by our adapted algorithms. Following previous experimental results, we only consider variant \maskalgo of each algorithm, and we always use the optimal window size for the whole dataset. Our experimental results reveal that none of the algorithm variants obtains the best compression performance in every scenario, which means that the selection of a variant depends on the characteristics of the data to be compressed, and the error threshold that is allowed. In some cases, even a general-purpose compression algorithm such as gzip outperforms the specific algorithm variant. Nevertheless, we extract some general conclusions from our analysis: for large error thresholds, variant \maskalgo of algorithm APCA achieves the best compression results, while algorithm gzip and variant \maskalgo of algorithm PCA are preferred for lower threshold scenarios.

\textbf{\textit{Keywords---}} multichannel signal compression, near-lossless compression, lossless compression, irregular sampling rate, data gaps.

}
\clearpage
