% Chapter 1

\chapter{Título del capítulo} % Main chapter title

\label{Capitulo1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Capítulo 1. \emph{Título del capítulo}} % This is for the header on each page - perhaps a shortened title

\newcommand{\maskalgo}{\textit{M}}
\newcommand{\NOmaskalgo}{\textit{NM}}
\newcommand{\difrelativa}{\textit{DiferenciaRelativa}}


\clearpage
\input{chapter1/table-datasets.tex}

En los experimentos realizados se codificaron los datasets combinando estos cuatro parámetros:
\vspace{-8pt}
\begin{itemize}
    \item 21 tipos de dato: ver tabla (\ref{tabla:resumen-de-los-datasets})
    \item 13 codificadores: 
        \begin{itemize}
            \item CoderBase
            \item CoderPCA-NM y CoderPCA-M
            \item CoderAPCA-NM y CoderAPCA-M
            \item CoderCA-NM y CoderCA-M
            \item CoderPWLH-NM y CoderPWLH-M
            \item CoderPWLHInt-NM y CoderPWLHInt-M
            \item CoderGampsLimit-NM y CoderGampsLimit-M
        \end{itemize}
    \item 8 umbrales de error: 0 (sin pérdida), y 1, 3, 5, 10, 15, 20 y 30 (con pérdida)
    \item 7 tamaños de ventana: 4, 8, 16, 32, 64, 128 y 256.
\end{itemize}

Algunas consideraciones a tener en cuenta:
\vspace{-8pt}
\begin{itemize}
    \item El codificador CoderBase solamente codifica sin pérdida e ignora el parámetro del tamaño de ventana. 
    \item Para los codificadores CoderPCA-NM y CoderPCA-M el tamaño de ventana es fijo, mientras que en el resto de los algoritmos (salvo CoderBase) el tamaño de ventana es variable y el parámetro indica su tamaño máximo.
\end{itemize}

\clearpage

Para comparar el rendimiento relativo de los algoritmos con ($\maskalgo$) y sin ($\NOmaskalgo$) máscara, utilizamos la siguiente ecuación
\vspace{-8pt}
\newcommand{\nmbits}{\NOmaskalgo_{\textit{S}}}
\newcommand{\mbits}{\maskalgo_\textit{S}}
\begin{equation}
\label{eq:diferencia-relativa}
%
 \difrelativa(\mbits, \nmbits)  =
  \begin{cases}
   100\times\frac{\nmbits - \mbits}{ \nmbits }, \quad & \text{si } \nmbits \ne \mbits, \\
   0,                   & \text{si } \nmbits = \mbits,
  \end{cases}
%  
\end{equation}
donde $\mbits$ y $\nmbits$ son los tamaños de los archivos codificados con los respectivos algoritmos. El algoritmo $\maskalgo$ logra una mejor tasa de compresión que el algoritmo $\NOmaskalgo$ cuando el resultado de la ecuación \ref{eq:diferencia-relativa} es mayor a cero. Mientras mayor sea dicho valor, mejor será el rendimiento relativo del algoritmo $\maskalgo$ respecto al algoritmo $\NOmaskalgo$.

[Se considera el dataset de manera global, tomando la ventana óptima global por algoritmo en cada caso. NOTA: para un umbral de error y modo fijo, la ventana óptima global no tiene por qué ser la misma para todos los algoritmos.]

En la tabla \ref{tabla:rendimiento-relativ-NM-M} se muestra un resumen de los resultados obtenidos al comparar el rendimiento relativo de los algoritmos $\NOmaskalgo$ y $\maskalgo$ para cada cada dataset. En la tercera y cuarta columnas aparece el porcentaje de las combinaciones <tipo de dato, codificador, umbral> con las que se obtiene la mejor tasa con cada algoritmo. En la última columna se muestra el rango en el que varía el resultado de la ecuación $\difrelativa$ para dichas combinaciones.

En los datasets que tienen muchos gaps siempre se obtienen mejores tasas al utilizar los algoritmos $\maskalgo$. En cambio, en los datasets sin gaps siempre se tiene mejor rendimiento con los algoritmos $\NOmaskalgo$. En el dataset con pocos gaps, en cada mitad de las combinaciones se obtienen mejores tasas con algoritmos diferentes.\\

\vspace{-5pt}
\input{chapter1/table-relative.tex}
\vspace{-10pt}

Observamos que, en los casos en los que se obtienen mejores tasas con el algoritmo $\NOmaskalgo$, la diferencia relativa siempre está cerca de 0. En la figura \ref{fig:diff-tornado} vemos que la mejor diferencia relativa a favor de $\NOmaskalgo$ se obtiene para el tipo de dato ``Longitude" del dataset NOAA-SPC-tornado, con el codificador CoderAPCA-$\NOmaskalgo$ y umbral de error 30\%. Como se observa en la tabla \ref{tabla:rendimiento-relativ-NM-M}, dicho valor es~$-0,29$.

Por otro lado, cuando se logran mejores tasas con el algoritmo $\maskalgo$ las diferencias relativas son mucho mayores, alcanzando un máximo de 50,60 para el tipo de dato ``VWC" del dataset NOAA-SST. En la figura \ref{fig:diff-sst} vemos que dicho resultado se obtiene con el codificador CoderPCA-$\maskalgo$ y umbral de error 30\%.

Teniendo en cuenta los resultados presentados, si quisiéramos codificar un dataset que a priori supiéramos tiene muchos gaps, obviamente nos convendría utilizar el algoritmo $\maskalgo$. Pero aún si el dataset no tuviera gaps, la diferencia de rendimiento a favor del algoritmo $\NOmaskalgo$ sería despreciable. Como el algoritmo $\maskalgo$ es más robusto y funciona mejor en general, en las próximas secciones nos vamos a enfocar en su estudio.

\begin{figure}
\hspace{-35pt}
\includegraphics[scale=0.35]{chapter1/7-NOAA-SPC-tornado-2.png}
\hspace{+10pt}
\caption{Tasa de compresión y Diferencia relativa\\para las distintas combinaciones <codificador, umbral de error>\\para el tipo de dato ``Longitude" del dataset Tornado.}
\label{fig:diff-tornado}
\end{figure}

\begin{figure}
\hspace{-35pt}
\includegraphics[scale=0.35]{chapter1/Global-2-NOAA-SST.png}
\hspace{+10pt}
\caption{Tasa de compresión y Diferencia relativa\\para las distintas combinaciones <codificador, umbral>\\para el dataset SST.}
\label{fig:diff-sst}
\end{figure}


